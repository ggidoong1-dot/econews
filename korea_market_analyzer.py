"""
í•œêµ­ ì‹œì¥ ì˜í–¥ ë¶„ì„ê¸°
ê¸€ë¡œë²Œ ë‰´ìŠ¤ê°€ í•œêµ­ ì£¼ì‹ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ AIë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
"""
import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timezone
import config

logger = config.setup_logger(__name__)

# Gemini API - API í‚¤ê°€ ìˆì„ ë•Œë§Œ ì´ˆê¸°í™”
GEMINI_AVAILABLE = False
if config.GOOGLE_API_KEY:
    try:
        import google.generativeai as genai
        genai.configure(api_key=config.GOOGLE_API_KEY)
        GEMINI_AVAILABLE = True
        logger.info("âœ… Gemini API ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
else:
    logger.info("â„¹ï¸ GOOGLE_API_KEY ë¯¸ì„¤ì • - ê·œì¹™ ê¸°ë°˜ ë¶„ì„ ì‚¬ìš©")


# ==============================================
# ì„¹í„°-ì¢…ëª© ë§¤í•‘ ë°ì´í„°
# ==============================================
SECTOR_STOCKS = {
    "ë°˜ë„ì²´": [
        {"code": "005930", "name": "ì‚¼ì„±ì „ì", "weight": "high"},
        {"code": "000660", "name": "SKí•˜ì´ë‹‰ìŠ¤", "weight": "high"},
        {"code": "005935", "name": "ì‚¼ì„±ì „ììš°", "weight": "medium"},
    ],
    "2ì°¨ì „ì§€": [
        {"code": "373220", "name": "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "weight": "high"},
        {"code": "006400", "name": "ì‚¼ì„±SDI", "weight": "high"},
        {"code": "247540", "name": "ì—ì½”í”„ë¡œë¹„ì— ", "weight": "medium"},
        {"code": "086520", "name": "ì—ì½”í”„ë¡œ", "weight": "medium"},
    ],
    "ìë™ì°¨": [
        {"code": "005380", "name": "í˜„ëŒ€ì°¨", "weight": "high"},
        {"code": "000270", "name": "ê¸°ì•„", "weight": "high"},
        {"code": "012330", "name": "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "weight": "medium"},
    ],
    "ë°”ì´ì˜¤": [
        {"code": "207940", "name": "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "weight": "high"},
        {"code": "068270", "name": "ì…€íŠ¸ë¦¬ì˜¨", "weight": "high"},
        {"code": "326030", "name": "SKë°”ì´ì˜¤íŒœ", "weight": "medium"},
    ],
    "IT/ì¸í„°ë„·": [
        {"code": "035420", "name": "NAVER", "weight": "high"},
        {"code": "035720", "name": "ì¹´ì¹´ì˜¤", "weight": "high"},
        {"code": "263750", "name": "í„ì–´ë¹„ìŠ¤", "weight": "low"},
    ],
    "ê¸ˆìœµ": [
        {"code": "105560", "name": "KBê¸ˆìœµ", "weight": "high"},
        {"code": "055550", "name": "ì‹ í•œì§€ì£¼", "weight": "high"},
        {"code": "316140", "name": "ìš°ë¦¬ê¸ˆìœµì§€ì£¼", "weight": "medium"},
    ],
    "ì¡°ì„ ": [
        {"code": "329180", "name": "HDí˜„ëŒ€ì¤‘ê³µì—…", "weight": "high"},
        {"code": "009540", "name": "HDí•œêµ­ì¡°ì„ í•´ì–‘", "weight": "high"},
        {"code": "010620", "name": "HDí˜„ëŒ€ë¯¸í¬", "weight": "medium"},
    ],
    "í™”í•™/ì •ìœ ": [
        {"code": "051910", "name": "LGí™”í•™", "weight": "high"},
        {"code": "096770", "name": "SKì´ë…¸ë² ì´ì…˜", "weight": "high"},
        {"code": "011170", "name": "ë¡¯ë°ì¼€ë¯¸ì¹¼", "weight": "medium"},
    ],
    "ì² ê°•": [
        {"code": "005490", "name": "POSCOí™€ë”©ìŠ¤", "weight": "high"},
        {"code": "004020", "name": "í˜„ëŒ€ì œì² ", "weight": "medium"},
    ],
    "ë°©ì‚°": [
        {"code": "012450", "name": "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤", "weight": "high"},
        {"code": "079550", "name": "LIGë„¥ìŠ¤ì›", "weight": "high"},
        {"code": "047810", "name": "í•œêµ­í•­ê³µìš°ì£¼", "weight": "medium"},
    ],
    "ì›ìë ¥": [
        {"code": "034020", "name": "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°", "weight": "high"},
        {"code": "052690", "name": "í•œì „ê¸°ìˆ ", "weight": "high"},
    ],
    "ì—”í„°": [
        {"code": "352820", "name": "HYBE", "weight": "high"},
        {"code": "035900", "name": "JYP Ent.", "weight": "medium"},
        {"code": "041510", "name": "SM", "weight": "medium"},
    ],
}


# ==============================================
# AI ê¸°ë°˜ í•œêµ­ ì‹œì¥ ì˜í–¥ ë¶„ì„
# ==============================================

def analyze_korea_impact(article: Dict) -> Optional[Dict]:
    """
    Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ì˜ í•œêµ­ ì‹œì¥ ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        article: ë‰´ìŠ¤ ê¸°ì‚¬ ë°ì´í„° (title, description, source ë“±)
        
    Returns:
        Dict: ì˜í–¥ ë¶„ì„ ê²°ê³¼
    """
    if not GEMINI_AVAILABLE:
        logger.warning("Gemini API ì‚¬ìš© ë¶ˆê°€. ê·œì¹™ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ í´ë°±.")
        return analyze_korea_impact_fallback(article)
    
    title = article.get('title', '')
    description = article.get('description', '')[:500]  # ê¸¸ì´ ì œí•œ
    source = article.get('source', '')
    
    prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ì‹œì¥ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì•„ë˜ ê¸€ë¡œë²Œ ë‰´ìŠ¤ê°€ í•œêµ­ ì£¼ì‹ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

[ë‰´ìŠ¤ ì •ë³´]
ì œëª©: {title}
ë‚´ìš©: {description}
ì¶œì²˜: {source}

[ë¶„ì„ ìš”ì²­]
ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

{{
    "korea_relevance": "high/medium/low/none",
    "impact_direction": "positive/negative/neutral",
    "confidence": 0.0-1.0,
    "affected_sectors": ["ì„¹í„°ëª…1", "ì„¹í„°ëª…2"],
    "reasoning": "í•œêµ­ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì„¤ëª… (í•œê¸€, 100ì ì´ë‚´)",
    "title_ko": "í•œê¸€ ì œëª© ë²ˆì—­"
}}

[ì£¼ì˜ì‚¬í•­]
- affected_sectorsëŠ” ë‹¤ìŒ ì¤‘ì—ì„œë§Œ ì„ íƒ: ë°˜ë„ì²´, 2ì°¨ì „ì§€, ìë™ì°¨, ë°”ì´ì˜¤, IT/ì¸í„°ë„·, ê¸ˆìœµ, ì¡°ì„ , í™”í•™/ì •ìœ , ì² ê°•, ë°©ì‚°, ì›ìë ¥, ì—”í„°
- korea_relevanceê°€ "none"ì´ë©´ ë‹¤ë¥¸ í•„ë“œëŠ” ê³µë°±ì´ë‚˜ ê¸°ë³¸ê°’ìœ¼ë¡œ ë‘ì„¸ìš”
- í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ confidenceë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ì„¸ìš”
"""
    
    try:
        model = genai.GenerativeModel(config.GEMINI_MODEL)
        response = model.generate_content(prompt)
        
        # JSON íŒŒì‹±
        text = response.text.strip()
        # ```json ë¸”ë¡ ì œê±°
        if text.startswith("```"):
            text = text.split("```")[1]
            if text.startswith("json"):
                text = text[4:]
        text = text.strip()
        
        result = json.loads(text)
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ["korea_relevance", "impact_direction", "affected_sectors"]
        for field in required_fields:
            if field not in result:
                result[field] = "none" if field == "korea_relevance" else []
        
        result["analysis_method"] = "gemini"
        return result
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return analyze_korea_impact_fallback(article)
    except Exception as e:
        logger.error(f"Gemini ë¶„ì„ ì‹¤íŒ¨: {e}")
        return analyze_korea_impact_fallback(article)


def analyze_korea_impact_fallback(article: Dict) -> Dict:
    """
    ê·œì¹™ ê¸°ë°˜ í•œêµ­ ì‹œì¥ ì˜í–¥ ë¶„ì„ (Gemini ì‹¤íŒ¨ ì‹œ í´ë°±).
    """
    from collectors.finance_rss import detect_affected_sectors, calculate_korea_relevance
    
    title = article.get('title', '')
    description = article.get('description', '')
    
    sectors = detect_affected_sectors(title, description)
    relevance = calculate_korea_relevance(title, description)
    
    # ê°ì • ë¶„ì„ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
    text_lower = f"{title} {description}".lower()
    
    negative_words = ["drop", "fall", "decline", "crash", "risk", "concern", 
                      "warning", "cut", "ban", "restrict", "sanction", "loss"]
    positive_words = ["rise", "gain", "surge", "boost", "strong", "growth",
                      "profit", "deal", "invest", "expand", "record"]
    
    neg_count = sum(1 for w in negative_words if w in text_lower)
    pos_count = sum(1 for w in positive_words if w in text_lower)
    
    if neg_count > pos_count:
        direction = "negative"
    elif pos_count > neg_count:
        direction = "positive"
    else:
        direction = "neutral"
    
    return {
        "korea_relevance": relevance,
        "impact_direction": direction,
        "confidence": 0.5,  # ê·œì¹™ ê¸°ë°˜ì€ ë‚®ì€ confidence
        "affected_sectors": sectors,
        "reasoning": "",
        "title_ko": "",
        "analysis_method": "rule_based"
    }


def get_recommended_stocks(sectors: List[str], direction: str) -> List[Dict]:
    """
    ì˜í–¥ë°›ëŠ” ì„¹í„°ì—ì„œ ì¢…ëª©ì„ ì¶”ì²œí•©ë‹ˆë‹¤.
    
    Args:
        sectors: ì˜í–¥ë°›ëŠ” ì„¹í„° ëª©ë¡
        direction: ì˜í–¥ ë°©í–¥ (positive/negative/neutral)
        
    Returns:
        List[Dict]: ì¶”ì²œ ì¢…ëª© ëª©ë¡
    """
    recommendations = []
    
    for sector in sectors:
        if sector not in SECTOR_STOCKS:
            continue
        
        stocks = SECTOR_STOCKS[sector]
        
        for stock in stocks:
            # ë†’ì€ ê°€ì¤‘ì¹˜ ì¢…ëª©ë§Œ ì¶”ì²œ
            if stock["weight"] in ["high", "medium"]:
                recommendations.append({
                    "code": stock["code"],
                    "name": stock["name"],
                    "sector": sector,
                    "direction": direction,
                    "weight": stock["weight"]
                })
    
    # ì¤‘ë³µ ì œê±° (ì¢…ëª© ì½”ë“œ ê¸°ì¤€)
    seen = set()
    unique_recs = []
    for rec in recommendations:
        if rec["code"] not in seen:
            seen.add(rec["code"])
            unique_recs.append(rec)
    
    # ê°€ì¤‘ì¹˜ ìˆœ ì •ë ¬
    weight_order = {"high": 0, "medium": 1, "low": 2}
    unique_recs.sort(key=lambda x: weight_order.get(x["weight"], 2))
    
    return unique_recs[:10]  # ìµœëŒ€ 10ê°œ


def analyze_news_batch(articles: List[Dict], use_ai: bool = True, rate_limit_delay: float = 5.0) -> List[Dict]:
    """
    ì—¬ëŸ¬ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë°°ì¹˜ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        articles: ë¶„ì„í•  ê¸°ì‚¬ ëª©ë¡
        use_ai: AI ë¶„ì„ ì‚¬ìš© ì—¬ë¶€ (Falseë©´ ê·œì¹™ ê¸°ë°˜ë§Œ ì‚¬ìš©)
        rate_limit_delay: API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ) - Gemini ë¬´ë£Œ ë²„ì „ì€ ë¶„ë‹¹ 15íšŒ ì œí•œ
        
    Returns:
        List[Dict]: ë¶„ì„ ê²°ê³¼ê°€ ì¶”ê°€ëœ ê¸°ì‚¬ ëª©ë¡
    """
    import time
    
    logger.info(f"ğŸ“Š í•œêµ­ ì‹œì¥ ì˜í–¥ ë¶„ì„ ì‹œì‘: {len(articles)}ê°œ ê¸°ì‚¬")
    
    analyzed = []
    korea_related = 0
    api_calls = 0
    
    for i, article in enumerate(articles):
        try:
            # AI ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ë¶„ì„ ë°©ë²• ì„ íƒ
            if use_ai and GEMINI_AVAILABLE:
                impact = analyze_korea_impact(article)
                api_calls += 1
                
                # Rate Limiting: Gemini ë¬´ë£Œ APIëŠ” ë¶„ë‹¹ 15íšŒ ì œí•œ
                # ì•ˆì „í•˜ê²Œ ë§¤ í˜¸ì¶œë§ˆë‹¤ 5ì´ˆ ëŒ€ê¸° (ë¶„ë‹¹ ìµœëŒ€ 12íšŒ)
                logger.debug(f"   â³ Rate limit ëŒ€ê¸° ({rate_limit_delay}ì´ˆ)...")
                time.sleep(rate_limit_delay)
            else:
                impact = analyze_korea_impact_fallback(article)
            
            if impact:
                article["korea_impact"] = impact
                
                # í•œêµ­ ê´€ë ¨ ê¸°ì‚¬ ì¹´ìš´íŠ¸
                if impact.get("korea_relevance") in ["high", "medium"]:
                    korea_related += 1
                    
                    # ì¶”ì²œ ì¢…ëª© ì¶”ê°€
                    if impact.get("affected_sectors"):
                        article["recommended_stocks"] = get_recommended_stocks(
                            impact["affected_sectors"],
                            impact.get("impact_direction", "neutral")
                        )
            
            analyzed.append(article)
            
            if (i + 1) % 10 == 0:
                logger.info(f"   ì§„í–‰: {i + 1}/{len(articles)} ({korea_related}ê°œ í•œêµ­ ê´€ë ¨)")
                
        except Exception as e:
            logger.error(f"   âŒ ê¸°ì‚¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            analyzed.append(article)
    
    logger.info(f"   âœ… ë¶„ì„ ì™„ë£Œ: {len(analyzed)}ê°œ ì¤‘ {korea_related}ê°œ í•œêµ­ ê´€ë ¨")
    return analyzed


def filter_high_impact_news(articles: List[Dict]) -> List[Dict]:
    """
    í•œêµ­ ì‹œì¥ì— ë†’ì€ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë‰´ìŠ¤ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    """
    high_impact = []
    
    for article in articles:
        impact = article.get("korea_impact", {})
        relevance = impact.get("korea_relevance", "none")
        
        if relevance in ["high", "medium"]:
            high_impact.append(article)
    
    # confidence ìˆœ ì •ë ¬
    high_impact.sort(
        key=lambda x: x.get("korea_impact", {}).get("confidence", 0),
        reverse=True
    )
    
    return high_impact


def format_impact_report(articles: List[Dict]) -> str:
    """
    í•œêµ­ ì‹œì¥ ì˜í–¥ ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    """
    high_impact = filter_high_impact_news(articles)
    
    if not high_impact:
        return "ğŸ“­ í•œêµ­ ì‹œì¥ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì£¼ìš” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    lines = [
        "ğŸ“° **í•œêµ­ ì‹œì¥ ì˜í–¥ ë‰´ìŠ¤**",
        f"ì´ {len(high_impact)}ê±´ì˜ ê´€ë ¨ ë‰´ìŠ¤",
        ""
    ]
    
    for i, article in enumerate(high_impact[:10], 1):
        impact = article.get("korea_impact", {})
        direction = impact.get("impact_direction", "neutral")
        
        emoji = {"positive": "ğŸŸ¢", "negative": "ğŸ”´", "neutral": "âšª"}.get(direction, "âšª")
        
        title_ko = impact.get("title_ko") or article.get("title", "")[:50]
        sectors = ", ".join(impact.get("affected_sectors", [])[:3])
        reasoning = impact.get("reasoning", "")[:80]
        
        lines.append(f"{i}. {emoji} **{title_ko}**")
        if sectors:
            lines.append(f"   ì˜í–¥ ì„¹í„°: {sectors}")
        if reasoning:
            lines.append(f"   â†’ {reasoning}")
        
        # ì¶”ì²œ ì¢…ëª©
        stocks = article.get("recommended_stocks", [])[:3]
        if stocks:
            stock_names = ", ".join([s["name"] for s in stocks])
            lines.append(f"   ğŸ’¡ ê´€ë ¨ ì¢…ëª©: {stock_names}")
        
        lines.append("")
    
    return "\n".join(lines)


# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    # ìƒ˜í”Œ ê¸°ì‚¬ë¡œ í…ŒìŠ¤íŠ¸
    sample_articles = [
        {
            "title": "Samsung Electronics Q4 profit drops 30% amid chip downturn",
            "description": "Samsung Electronics reported a 30% decline in fourth-quarter operating profit due to weak memory chip demand.",
            "source": "WSJ"
        },
        {
            "title": "Tesla to expand battery production with new suppliers",
            "description": "Tesla announced plans to significantly expand its battery supply chain, potentially benefiting Asian suppliers.",
            "source": "BBC Business"
        },
        {
            "title": "Fed signals potential rate cut in upcoming meeting",
            "description": "The Federal Reserve indicated it may reduce interest rates, boosting global market sentiment.",
            "source": "NPR Business"
        }
    ]
    
    print("í•œêµ­ ì‹œì¥ ì˜í–¥ ë¶„ì„ í…ŒìŠ¤íŠ¸...")
    analyzed = analyze_news_batch(sample_articles)
    print(format_impact_report(analyzed))
