#!/usr/bin/env python3
"""
Naver ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ë””ë²„ê·¸ ë„êµ¬
í˜„ì¬ HTML êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ì˜¬ë°”ë¥¸ CSS selectorë¥¼ ì°¾ìŠµë‹ˆë‹¤.
"""
import requests
from bs4 import BeautifulSoup
import urllib.parse

def test_naver_structure(keyword="ì›°ë‹¤ì‰"):
    """Naver ë‰´ìŠ¤ êµ¬ì¡° ë¶„ì„"""
    print("=" * 70)
    print("ğŸ” Naver ë‰´ìŠ¤ HTML êµ¬ì¡° ë¶„ì„")
    print("=" * 70)
    
    encoded = urllib.parse.quote(keyword)
    url = f"https://search.naver.com/search.naver?where=news&query={encoded}&sort=1"
    
    print(f"\nê²€ìƒ‰ì–´: {keyword}")
    print(f"URL: {url}\n")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        print(f"âœ… HTTP Status: {response.status_code}\n")
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë‹¤ì–‘í•œ ì…€ë ‰í„° ì‹œë„
        selectors_to_try = [
            ('a.news_tit', 'ê¸°ë³¸ ì…€ë ‰í„°'),
            ('.news_area .news_tit', 'ë‰´ìŠ¤ ì˜ì—­ ë‚´ ì œëª©'),
            ('div.news_wrap a.news_tit', 'ë‰´ìŠ¤ ë˜í¼ ë‚´ ì œëª©'),
            ('a[href*="n.news.naver.com"]', 'URL íŒ¨í„´ ê¸°ë°˜'),
            ('.news_contents a', 'ë‰´ìŠ¤ ì»¨í…ì¸  ë§í¬'),
            ('div.group_news a', 'ê·¸ë£¹ ë‰´ìŠ¤ ë§í¬'),
            ('a.api_txt_lines', 'API í…ìŠ¤íŠ¸ ë¼ì¸'),
        ]
        
        print("ğŸ“‹ ì…€ë ‰í„° í…ŒìŠ¤íŠ¸ ê²°ê³¼:\n")
        
        working_selectors = []
        
        for selector, description in selectors_to_try:
            items = soup.select(selector)
            print(f"[{len(items):3d}ê°œ] {selector:40s} - {description}")
            
            if items:
                working_selectors.append((selector, items))
        
        # ê°€ì¥ ë§ì´ ì°¾ì€ ì…€ë ‰í„° ìƒì„¸ ë¶„ì„
        if working_selectors:
            print("\n" + "=" * 70)
            print("âœ… ì‘ë™í•˜ëŠ” ì…€ë ‰í„° ë°œê²¬!")
            print("=" * 70)
            
            # ê°œìˆ˜ê°€ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬
            working_selectors.sort(key=lambda x: len(x[1]), reverse=True)
            
            best_selector, items = working_selectors[0]
            
            print(f"\nğŸ¯ ì¶”ì²œ ì…€ë ‰í„°: {best_selector}")
            print(f"   ë°œê²¬ëœ í•­ëª©: {len(items)}ê°œ\n")
            
            print("ğŸ“° ì²« 5ê°œ ê¸°ì‚¬ ë¯¸ë¦¬ë³´ê¸°:\n")
            for i, item in enumerate(items[:5], 1):
                title = item.get_text(strip=True)
                link = item.get('href', '')
                
                print(f"{i}. {title[:60]}...")
                print(f"   ë§í¬: {link[:80]}...\n")
            
            # HTML ìƒ˜í”Œ ì €ì¥
            sample_file = '/home/claude/naver_sample.html'
            with open(sample_file, 'w', encoding='utf-8') as f:
                # ì²« ë²ˆì§¸ ë‰´ìŠ¤ í•­ëª©ì˜ HTML êµ¬ì¡° ì €ì¥
                if items:
                    parent = items[0].find_parent()
                    if parent:
                        f.write(str(parent.prettify()))
            
            print(f"ğŸ’¾ HTML ìƒ˜í”Œ ì €ì¥: {sample_file}")
            
        else:
            print("\n" + "=" * 70)
            print("âŒ ì‘ë™í•˜ëŠ” ì…€ë ‰í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            print("=" * 70)
            
            # ì „ì²´ HTML ì €ì¥ (ë””ë²„ê¹…ìš©)
            debug_file = '/home/claude/naver_full_debug.html'
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f"\nğŸ’¾ ì „ì²´ HTML ì €ì¥: {debug_file}")
            print("   íŒŒì¼ì„ ì—´ì–´ì„œ HTML êµ¬ì¡°ë¥¼ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
            # ëª¨ë“  <a> íƒœê·¸ ë¶„ì„
            all_links = soup.find_all('a', href=True)
            naver_news_links = [a for a in all_links if 'news.naver.com' in a.get('href', '')]
            
            print(f"\nğŸ“Š ì „ì²´ ë§í¬ í†µê³„:")
            print(f"   ì´ <a> íƒœê·¸: {len(all_links)}ê°œ")
            print(f"   Naver ë‰´ìŠ¤ ë§í¬: {len(naver_news_links)}ê°œ")
            
            if naver_news_links:
                print(f"\nğŸ”— Naver ë‰´ìŠ¤ ë§í¬ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
                for i, link in enumerate(naver_news_links[:3], 1):
                    print(f"\n{i}. í…ìŠ¤íŠ¸: {link.get_text(strip=True)[:50]}...")
                    print(f"   í´ë˜ìŠ¤: {link.get('class', [])}")
                    print(f"   URL: {link['href'][:80]}...")
        
        print("\n" + "=" * 70)
        print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print("=" * 70)
        
    except requests.exceptions.Timeout:
        print("âŒ íƒ€ì„ì•„ì›ƒ (10ì´ˆ)")
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    import sys
    
    keyword = sys.argv[1] if len(sys.argv) > 1 else "ì›°ë‹¤ì‰"
    test_naver_structure(keyword)
