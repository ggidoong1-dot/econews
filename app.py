"""
Streamlit ëŒ€ì‹œë³´ë“œ (v3.4) - í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì¶”ê°€
Well-Dying Archive ê´€ë¦¬ ë° ëª¨ë‹ˆí„°ë§
"""
import streamlit as st
import pandas as pd
import requests
import os
from datetime import datetime, timezone, timedelta
import config
import database as db

# =============================================================================
# í˜ì´ì§€ ì„¤ì • & CSS
# =============================================================================
st.set_page_config(
    page_title="Global Well-Dying Archive",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë‹¤í¬ ë„¤ì´ë¹„ í…Œë§ˆ
st.markdown("""
<style>
    .main { background-color: #1e2936; }
    .block-container { padding-top: 2rem; padding-bottom: 2rem; max-width: 95%; } /* í™”ë©´ ë„“ê²Œ ì‚¬ìš© */
    
    h1 { color: #e8edf2; font-weight: 600; font-size: 2.2rem !important; margin-bottom: 0.5rem; }
    h2, h3, h4 { color: #d4dce5; font-weight: 500; }
    p, label, .stMarkdown { color: #a8b4c0; }
    
    /* ë©”íŠ¸ë¦­ ìŠ¤íƒ€ì¼ */
    [data-testid="stMetricValue"] { font-size: 1.8rem; font-weight: 600; color: #e8edf2; }
    [data-testid="stMetricLabel"] { color: #7a8a99; font-size: 0.75rem; text-transform: uppercase; }
    
    /* ì‚¬ì´ë“œë°” */
    [data-testid="stSidebar"] { background-color: #16202c; border-right: 1px solid #2a3847; }
    
    /* í…Œì´ë¸” ìŠ¤íƒ€ì¼ */
    .stDataFrame { background-color: #16202c; border: 1px solid #2a3847; border-radius: 8px; }
    
    hr { margin: 2rem 0; border: none; height: 1px; background-color: #2a3847; }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================
def get_flag_emoji(country):
    """êµ­ê°€ëª…ì„ êµ­ê¸° ì´ëª¨ì§€ë¡œ ë³€í™˜"""
    if not country or country == 'Unknown': return "ğŸŒ"
    country = str(country).upper().strip()
    mapping = {
        'KOREA': 'ğŸ‡°ğŸ‡·', 'KR': 'ğŸ‡°ğŸ‡·', 'SOUTH KOREA': 'ğŸ‡°ğŸ‡·',
        'USA': 'ğŸ‡ºğŸ‡¸', 'US': 'ğŸ‡ºğŸ‡¸', 'UNITED STATES': 'ğŸ‡ºğŸ‡¸',
        'UK': 'ğŸ‡¬ğŸ‡§', 'UNITED KINGDOM': 'ğŸ‡¬ğŸ‡§', 'GB': 'ğŸ‡¬ğŸ‡§',
        'GLOBAL': 'ğŸŒ', 'WORLD': 'ğŸŒ', 'INTERNATIONAL': 'ğŸŒ',
        'JAPAN': 'ğŸ‡¯ğŸ‡µ', 'JP': 'ğŸ‡¯ğŸ‡µ', 'CANADA': 'ğŸ‡¨ğŸ‡¦', 'CA': 'ğŸ‡¨ğŸ‡¦',
        'AUSTRALIA': 'ğŸ‡¦ğŸ‡º', 'AU': 'ğŸ‡¦ğŸ‡º', 'FRANCE': 'ğŸ‡«ğŸ‡·', 'FR': 'ğŸ‡«ğŸ‡·',
        'GERMANY': 'ğŸ‡©ğŸ‡ª', 'DE': 'ğŸ‡©ğŸ‡ª', 'NETHERLANDS': 'ğŸ‡³ğŸ‡±', 'NL': 'ğŸ‡³ğŸ‡±',
        'SWITZERLAND': 'ğŸ‡¨ğŸ‡­', 'CH': 'ğŸ‡¨ğŸ‡­', 'SPAIN': 'ğŸ‡ªğŸ‡¸', 'ES': 'ğŸ‡ªğŸ‡¸',
        'ITALY': 'ğŸ‡®ğŸ‡¹', 'IT': 'ğŸ‡®ğŸ‡¹',
    }
    return mapping.get(country, 'ğŸŒ')

def trigger_github_action(workflow_id: str = "morning_briefing.yml"):
    """GitHub Actions ì›Œí¬í”Œë¡œìš° íŠ¸ë¦¬ê±°"""
    token = os.getenv("GITHUB_PAT")
    owner = os.getenv("GITHUB_OWNER", "ggidoong1-dot")
    repo = os.getenv("GITHUB_REPO", "econews")
    
    if not token: return False, "âŒ GITHUB_PAT í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    url = f"https://api.github.com/repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches"
    headers = {"Accept": "application/vnd.github.v3+json", "Authorization": f"token {token}"}
    data = {"ref": "main"}
    
    try:
        response = requests.post(url, headers=headers, json=data, timeout=10)
        return (True, "ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹œì‘ë¨!") if response.status_code == 204 else (False, f"âŒ ì‹¤íŒ¨ ({response.status_code})")
    except Exception as e:
        return False, f"âŒ ì—ëŸ¬: {str(e)}"

def run_morning_briefing_local():
    """ë¡œì»¬ì—ì„œ ëª¨ë‹ ë¸Œë¦¬í•‘ ì‹¤í–‰ (Streamlit Cloudìš©)"""
    try:
        from morning_briefing import generate_morning_briefing
        briefing = generate_morning_briefing()
        return True, briefing
    except Exception as e:
        return False, f"âŒ ì—ëŸ¬: {str(e)}"

# =============================================================================
# ë°ì´í„° ë¡œë”© í•¨ìˆ˜
# =============================================================================
@st.cache_data(ttl=300)
def load_news_data(days=7):
    try:
        cutoff = (datetime.now(timezone.utc) - timedelta(days=days)).isoformat()
        response = db.supabase.table("news").select("*").gte("created_at", cutoff).order("created_at", desc=True).limit(1000).execute()
        if not response.data: return pd.DataFrame()
        
        df = pd.DataFrame(response.data)
        df['created_at'] = pd.to_datetime(df['created_at'], format='mixed')
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        df['title_ko'] = df['title_ko'].fillna(df['title'])
        df['country'] = df['country'].fillna('Global')
        df['source'] = df['source'].fillna('Unknown')
        df['quality_score'] = df['quality_score'].fillna(0)
        df['flag'] = df['country'].apply(get_flag_emoji)
        
        # [í•µì‹¬] ìš”ì•½ ë°ì´í„° í†µí•© (summary_ai ìš°ì„ )
        if 'summary_ai' not in df.columns: df['summary_ai'] = None
        if 'summary' not in df.columns: df['summary'] = None
        
        # ìš”ì•½ì´ ì—†ìœ¼ë©´ 'ëŒ€ê¸° ì¤‘' í‘œì‹œ
        df['final_summary'] = df['summary_ai'].fillna(df['summary']).fillna('â³ ë¶„ì„ ëŒ€ê¸° ì¤‘...')
        
        return df
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=300)
def load_reports():
    try:
        response = db.supabase.table("daily_reports").select("*").order("report_date", desc=True).limit(30).execute()
        return response.data if response.data else []
    except: return []

# =============================================================================
# ë©”ì¸ ë ˆì´ì•„ì›ƒ
# =============================================================================
st.title("ğŸ’° ì˜¤ëŠ˜ì„ ìœ„í•œ ê²½ì œí”½")
st.caption("AI-Powered News Monitoring & Intelligence System (v3.3)")
st.markdown("---")

tab_feed, tab_ai, tab_reports, tab_quality, tab_admin = st.tabs(["ğŸ“‹ News Feed", "ğŸ¤– AI Insights", "ğŸ“Š Daily Reports", "ğŸ“ˆ Quality Monitor", "âš™ï¸ Management"])
df = pd.DataFrame()

# =============================================================================
# TAB 1: News Feed (í‘œ í˜•ì‹ ì „ìš©)
# =============================================================================
with tab_feed:
    with st.sidebar:
        st.markdown("### ğŸ” Filters")
        st.markdown("")
        search_query = st.text_input("Search", placeholder="Search...", label_visibility="collapsed")
        date_range = st.selectbox("Date Range", ["Last 7 Days", "Last 30 Days", "Last 90 Days", "All Time"])
        days_map = {"Last 7 Days": 7, "Last 30 Days": 30, "Last 90 Days": 90, "All Time": 365}
        
        df = load_news_data(days=days_map[date_range])
        
        if not df.empty:
            countries = ['All'] + sorted(df['country'].unique().tolist())
            selected_country = st.selectbox("Country", countries)
            sources = ['All'] + sorted(df['source'].unique().tolist())
            selected_source = st.selectbox("Source", sources)
            process_filter = st.selectbox("Status", ["All", "Analyzed", "Not Analyzed"])

    if df.empty:
        st.info("ğŸ“­ ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ìƒë‹¨ í†µê³„
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ğŸ“° ì „ì²´ ê¸°ì‚¬", f"{len(df):,}ê±´")
        c2.metric("ğŸ¤– ë¶„ì„ ì™„ë£Œ", f"{df['is_processed'].sum():,}ê±´")
        avg_qual = df[df['quality_score'] > 0]['quality_score'].mean()
        c3.metric("â­ í‰ê·  í’ˆì§ˆ", f"{avg_qual:.0f}ì " if not pd.isna(avg_qual) else "N/A")
        
        # [ì˜¤ë¥˜ ìˆ˜ì •ëœ ë¶€ë¶„]
        c4.metric("ğŸ“¡ ì¶œì²˜ ìˆ˜", f"{df['source'].nunique()}ê°œ")
        
        st.markdown("---")
        
        # í•„í„°ë§
        filtered_df = df.copy()
        if search_query:
            mask = (filtered_df['title'].str.contains(search_query, case=False, na=False) |
                    filtered_df['title_ko'].str.contains(search_query, case=False, na=False))
            filtered_df = filtered_df[mask]
        if selected_country != 'All': filtered_df = filtered_df[filtered_df['country'] == selected_country]
        if selected_source != 'All': filtered_df = filtered_df[filtered_df['source'] == selected_source]
        if process_filter == "Analyzed": filtered_df = filtered_df[filtered_df['is_processed'] == True]
        elif process_filter == "Not Analyzed": filtered_df = filtered_df[filtered_df['is_processed'] == False]
        
        st.caption(f"ì´ {len(filtered_df)}ê°œì˜ ê¸°ì‚¬ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")

        if filtered_df.empty:
            st.info("ì¡°ê±´ì— ë§ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # =========================================================
            # [ìµœì¢…] ì—‘ì…€ ìŠ¤íƒ€ì¼ í‘œ (Table View)
            # =========================================================
            # í‘œì‹œí•  ì»¬ëŸ¼ ì •ë¦¬
            display_df = filtered_df[[
                'created_at', 'flag', 'title_ko', 'final_summary', 
                'source', 'sentiment', 'quality_score', 'link'
            ]].copy()
            
            # í•œê¸€ ì»¬ëŸ¼ëª… ë§¤í•‘
            display_df.columns = ['ë‚ ì§œ', 'êµ­ê°€', 'ì œëª© (í•œêµ­ì–´)', 'AI 3ì¤„ ìš”ì•½', 'ì¶œì²˜', 'ê°ì •', 'í’ˆì§ˆ', 'ë§í¬']
            
            st.dataframe(
                display_df,
                use_container_width=True,
                hide_index=True,
                height=800, # í‘œ ë†’ì´ ë„‰ë„‰í•˜ê²Œ
                column_config={
                    "ë‚ ì§œ": st.column_config.DatetimeColumn(
                        "ì‘ì„±ì¼", 
                        format="MM-DD HH:mm", 
                        width="small"
                    ),
                    "êµ­ê°€": st.column_config.TextColumn("êµ­ê°€", width="small"),
                    "ì œëª© (í•œêµ­ì–´)": st.column_config.TextColumn(
                        "ê¸°ì‚¬ ì œëª©", 
                        width="medium",
                        help="ì›ë¬¸ ì œëª©ì€ ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë¦¬ë©´ ë³´ì…ë‹ˆë‹¤."
                    ),
                    # [í•µì‹¬] ìš”ì•½ ì»¬ëŸ¼ì„ ë„“ê²Œ ì„¤ì •
                    "AI 3ì¤„ ìš”ì•½": st.column_config.TextColumn(
                        "AI ìš”ì•½ ë‚´ìš©", 
                        width="large", # ê°€ì¥ ë„“ê²Œ ë°°ì •
                        help="ğŸ’¡ ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë¦¬ê±°ë‚˜ ë”ë¸” í´ë¦­í•˜ë©´ ì „ì²´ ìš”ì•½ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    ),
                    "ì¶œì²˜": st.column_config.TextColumn("ì¶œì²˜", width="small"),
                    "ê°ì •": st.column_config.TextColumn("ê°ì •", width="small"),
                    "í’ˆì§ˆ": st.column_config.ProgressColumn(
                        "í’ˆì§ˆ", 
                        format="%d", 
                        min_value=0, 
                        max_value=100,
                        width="small"
                    ),
                    "ë§í¬": st.column_config.LinkColumn(
                        "ì›ë¬¸", 
                        display_text="ğŸ”— ì´ë™", 
                        width="small"
                    )
                }
            )

# =============================================================================
# TAB 2~4 (ê¸°ëŠ¥ ìœ ì§€)
# =============================================================================
with tab_ai:
    st.markdown("### ğŸ§  AI Analysis Dashboard")
    if df.empty: st.info("ğŸ“­ No data.")
    else:
        ai_df = df[df['is_processed'] == True]
        if ai_df.empty: st.info("ğŸ¤– No analyzed data.")
        else:
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("Analyzed", len(ai_df))
            c2.metric("Positive", len(ai_df[ai_df['sentiment']=='Positive']))
            c3.metric("Negative", len(ai_df[ai_df['sentiment']=='Negative']))
            c4.metric("Neutral", len(ai_df[ai_df['sentiment']=='Neutral']))
            st.dataframe(ai_df[['title_ko', 'category', 'sentiment', 'quality_score']], use_container_width=True)

with tab_reports:
    st.markdown("### ğŸ“Š Daily Briefing Archive")
    reports = load_reports()
    if not reports: st.info("ğŸ“­ No reports.")
    else:
        for r in reports:
            with st.expander(f"ğŸ“¢ {r.get('report_date')}"):
                st.markdown(r['content'])

# =============================================================================
# TAB 4: Quality Monitor (ì‹ ê·œ)
# =============================================================================
with tab_quality:
    st.markdown("### ğŸ“ˆ ìˆ˜ì§‘ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§")
    st.caption("ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œìŠ¤í…œì˜ ê±´ê°• ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.")
    
    # í’ˆì§ˆ ë©”íŠ¸ë¦­ ë¡œë“œ
    try:
        metrics = db.get_collection_quality_metrics(days=1)
        
        # ì£¼ìš” ì§€í‘œ
        col1, col2, col3, col4 = st.columns(4)
        col1.metric(
            "ğŸ“¥ 24ì‹œê°„ ìˆ˜ì§‘ëŸ‰", 
            f"{metrics.get('total_collected', 0):,}ê±´",
            help="ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ ìˆ˜ì§‘ëœ ì´ ê¸°ì‚¬ ìˆ˜"
        )
        col2.metric(
            "âœ… ë¶„ì„ ì™„ë£Œ", 
            f"{metrics.get('total_processed', 0):,}ê±´",
            delta=f"{metrics.get('success_rate', 0):.1f}%"
        )
        col3.metric(
            "â­ ê³ í’ˆì§ˆ ê¸°ì‚¬", 
            f"{metrics.get('high_quality_count', 0):,}ê±´",
            delta=f"{metrics.get('quality_rate', 0):.1f}%"
        )
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        source_health = metrics.get('source_health', {})
        healthy_count = sum(1 for s in source_health.values() if s.get('status') == 'healthy')
        total_sources = len(source_health)
        system_status = "ğŸŸ¢ ì •ìƒ" if healthy_count >= total_sources * 0.7 else "ğŸŸ¡ ì£¼ì˜" if healthy_count >= total_sources * 0.3 else "ğŸ”´ ê²½ê³ "
        col4.metric("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ", system_status)
        
        st.markdown("---")
        
        # ì†ŒìŠ¤ë³„ ìƒíƒœ
        st.markdown("#### ğŸ“¡ ë‰´ìŠ¤ ì†ŒìŠ¤ ìƒíƒœ")
        if source_health:
            source_data = []
            for source, info in source_health.items():
                status = info.get('status', 'unknown')
                status_emoji = {"healthy": "ğŸŸ¢", "warning": "ğŸŸ¡", "critical": "ğŸ”´"}.get(status, "âšª")
                source_data.append({
                    "ì†ŒìŠ¤": source,
                    "ìƒíƒœ": f"{status_emoji} {status.upper()}",
                    "ìˆ˜ì§‘ëŸ‰": info.get('count', 0)
                })
            
            source_df = pd.DataFrame(source_data)
            st.dataframe(source_df, use_container_width=True, hide_index=True)
        else:
            st.info("ì†ŒìŠ¤ ìƒíƒœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„
        st.caption(f"ğŸ•’ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {metrics.get('timestamp', 'N/A')}")
        
    except Exception as e:
        st.error(f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.info("ğŸ’¡ database.pyì˜ get_collection_quality_metrics() í•¨ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

with tab_admin:
    st.markdown("### âš™ï¸ System Management")
    
    # ëª¨ë‹ ë¸Œë¦¬í•‘ ì„¹ì…˜
    st.markdown("#### ğŸ“Š ëª¨ë‹ ë¸Œë¦¬í•‘")
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸŒ… ëª¨ë‹ ë¸Œë¦¬í•‘ ì‹¤í–‰ (ë¡œì»¬)", type="primary", use_container_width=True):
            with st.spinner("ë¸Œë¦¬í•‘ ìƒì„± ì¤‘... (ì•½ 30ì´ˆ ì†Œìš”)"):
                success, result = run_morning_briefing_local()
                if success:
                    st.success("âœ… ë¸Œë¦¬í•‘ ìƒì„± ì™„ë£Œ!")
                    st.text_area("ë¸Œë¦¬í•‘ ë‚´ìš©", result, height=400)
                else:
                    st.error(result)
    
    with col2:
        if st.button("â˜ï¸ GitHub Actions íŠ¸ë¦¬ê±°", use_container_width=True):
            s, m = trigger_github_action("morning_briefing.yml")
            if s: st.success(m)
            else: st.error(m)
    
    st.markdown("---")
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘ ì„¹ì…˜
    with st.expander("ğŸ“¡ ë‰´ìŠ¤ ìˆ˜ì§‘ (Collector)"):
        if st.button("âš¡ Run Collector", type="secondary"):
            from collector import run_collector
            with st.spinner("ìˆ˜ì§‘ ì¤‘..."):
                try:
                    result = run_collector()
                    st.success(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {result.get('inserted', 0)}ê°œ ì €ì¥")
                except Exception as e:
                    st.error(f"âŒ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("#### Keywords")
        st.dataframe(pd.DataFrame(db.get_keywords(), columns=["Keyword"]), use_container_width=True)
    with c2:
        st.markdown("#### Ban Words")
        st.dataframe(pd.DataFrame(db.get_ban_words(), columns=["Ban Word"]), use_container_width=True)